
# ğŸ§© Framework de Ingesta de Datos en AWS

Este repositorio contiene la infraestructura como cÃ³digo (IaC) para desplegar un **framework de ingesta de datos reutilizable y gobernado** en AWS. EstÃ¡ diseÃ±ado para facilitar el trabajo de:

- **Data Engineers**: configuraciÃ³n de nuevas ingestas, orquestaciÃ³n, transformaciÃ³n.
- **Equipos DevOps / Data Platform**: despliegue y mantenimiento de la infraestructura base del framework.

## ğŸ§± Arquitectura General

El framework se compone de tres zonas principales dentro de un Data Lake:

| Zona           | FunciÃ³n Principal                         | Servicios Principales                      |
|----------------|--------------------------------------------|--------------------------------------------|
| **Landing**    | RecepciÃ³n de datos crudos                  | S3, Lambda, DynamoDB                       |
| **Refined**    | TransformaciÃ³n y validaciÃ³n                | S3, Glue, Lambda, Data Catalog, DynamoDB   |
| **Trusted**    | PublicaciÃ³n de datos anonimizados confiables | S3, Lambda, Athena, DynamoDB, SNS          |

## ğŸ“ Estructura del Repositorio

```
terraform/
â”œâ”€â”€ modules/
â”‚   â”œâ”€â”€ s3_zones/
â”‚   â”œâ”€â”€ lambda_orchestrator/
â”‚   â”œâ”€â”€ glue_job/
â”‚   â”œâ”€â”€ dynamodb_config/
â”‚   â”œâ”€â”€ sns_alerts/
â”‚   â””â”€â”€ iam_roles/
â”œâ”€â”€ environments/
â”‚   â”œâ”€â”€ dev/
â”‚   â””â”€â”€ prod/
â”œâ”€â”€ data-config/
â”‚   â””â”€â”€ datasets/
â”œâ”€â”€ lambda_jobs/
â”‚   â”œâ”€â”€ orchestrator/
â”‚   â”œâ”€â”€ data_quality/
â”‚   â””â”€â”€ anonymizer/
â””â”€â”€ scripts/glue/
```

## ğŸš€ Despliegue de la Infraestructura Base (DevOps)

### 1. Requisitos

- AWS CLI configurado
- Terraform â‰¥ 1.3.0
- Permisos para crear recursos (S3, Lambda, Glue, DynamoDB, IAM)

### 2. Variables clave

- `env`: entorno (`dev`, `prod`, etc.)
- `resource_prefix`: prefijo para identificar recursos del framework (por defecto `dlgi_`)

### 3. Pasos de despliegue

```bash
cd terraform/environments/dev

terraform init
terraform apply -var="env=dev" -var="resource_prefix=dlgi_"
```

## âš™ï¸ ConfiguraciÃ³n de nuevas ingestas (Data Engineers)

Cada dataset se declara como un archivo Terraform en `data-config/datasets/`.

### Ejemplo: `clientes_ingesta.tf`

```hcl
resource "aws_dynamodb_table_item" "ingesta_clientes" {
  table_name = "dlgi_ingesta_config_dev"
  hash_key   = "dataset_name"

  item = <<ITEM
{
  "dataset_name": {"S": "clientes"},
  "job_type": {"S": "glue"},
  "frecuencia": {"S": "diaria"},
  "path_landing": {"S": "clientes/"},
  "output_table": {"S": "clientes_refined"}
}
ITEM
}
```

### Aplicar cambios:

```bash
cd terraform/data-config
terraform init
terraform apply -var="env=dev" -var="resource_prefix=dlgi_"
```

## ğŸ“¦ CÃ³digo fuente Lambda

Los siguientes lambdas estÃ¡n incluidos con su cÃ³digo de ejemplo en `lambda_jobs/`:

| Lambda             | FunciÃ³n                                     |
|--------------------|---------------------------------------------|
| `orchestrator`     | Decide el tipo de job a ejecutar (Glue o Lambda) |
| `data_quality`     | Aplica reglas bÃ¡sicas de calidad            |
| `anonymizer`       | Enmascara o elimina datos sensibles         |

## ğŸ§ª Glue ETL de ejemplo

Archivo: `scripts/glue/default_etl.py`

Funcionalidad:

- Lee desde `landing`
- Elimina duplicados
- Escribe en formato Parquet a `refined`

## ğŸ”’ Seguridad y Gobernanza

- Recursos con prefijo (`dlgi_`) para fÃ¡cil trazabilidad.
- IAM policy de ejemplo incluida.
- Compatible con Lake Formation para control avanzado.

## ğŸ“¬ Soporte

Contacta al equipo de Data Engineering o DevOps responsable del Lakehouse.
