# Framework de Ingesta de Datos en AWS ‚Äì Data Lake

Este repositorio documenta un framework gen√©rico y reutilizable para la **ingesta, transformaci√≥n y publicaci√≥n de datos** en un Data Lake sobre AWS. El objetivo es facilitar la incorporaci√≥n de nuevos datasets de forma **escalable, gobernada y automatizada**, siguiendo buenas pr√°cticas de arquitectura moderna.

---

## üß± Arquitectura General

La soluci√≥n se organiza en **tres zonas principales**:

### 1. **Landing Zone**
- Punto de entrada de los datos crudos desde distintas fuentes (FTP, buckets externos, etc.).
- Los archivos `.csv.gz` son integrados con Apache NiFi y almacenados temporalmente en un bucket S3.
- Un **orquestador Lambda** se activa por eventos y consulta la configuraci√≥n del dataset para decidir c√≥mo procesarlo (job ligero o pesado).
- La configuraci√≥n y cola de ingestas se almacenan en DynamoDB, lo que permite que el flujo sea completamente **din√°mico y escalable**.

### 2. **Refined Zone**
- Los datos ya transformados son almacenados en un bucket separado.
- Se ejecutan procesos de transformaci√≥n mediante:
  - **AWS Lambda** para cargas livianas.
  - **AWS Glue** para cargas pesadas (ETL complejas, grandes vol√∫menes).
- Los datasets se registran autom√°ticamente en el **AWS Glue Data Catalog**, y quedan disponibles en **Athena** bajo la base `db_refined`.
- Se registran logs de ingesta y metadatos t√©cnicos para trazabilidad.

### 3. **Trusted Zone**
- Se aplican validaciones de calidad mediante un job espec√≠fico (`Job DataQuality`), donde se generan m√©tricas de calidad y se notifican fallos (SNS).
- Luego se ejecuta el proceso de **anonimizaci√≥n**, aplicando enmascaramiento o eliminaci√≥n de PII.
- Los datos finales se almacenan en un bucket confiable (`trusted`) y expuestos en Athena como `db_trusted_analytics`, para el acceso de usuarios anal√≠ticos.

---

## üîÑ Flujo de Datos

1. Los datos llegan desde FTPS o buckets externos ‚Üí Apache NiFi los deposita en la **Landing Zone**.
2. Un trigger de evento activa un Lambda que consulta la configuraci√≥n en DynamoDB y dirige el flujo.
3. Se ejecuta el job ETL (Lambda o Glue) ‚Üí resultado se guarda en la **Refined Zone**.
4. Otro trigger activa el job de **Data Quality**.
5. Si pasa las validaciones, se ejecuta el job de **anonimizaci√≥n**.
6. El resultado final se publica en la **Trusted Zone**.

---

## üß© Componentes AWS utilizados

- **S3:** Almacenamiento por zonas (landing, refined, trusted).
- **Lambda:** Orquestaci√≥n, procesamiento ligero, control de calidad, anonimizaci√≥n.
- **Glue:** Procesamiento ETL pesado y cat√°logo de datos.
- **Athena:** Consulta de datos por parte de usuarios y analistas.
- **DynamoDB:** Configuraci√≥n de ingestas, colas, logs t√©cnicos.
- **SNS:** Notificaciones sobre validaciones de calidad y errores.

---

## üéØ Beneficios del Framework

- **Reutilizable:** Admite m√∫ltiples pipelines sin reescribir c√≥digo.
- **Escalable:** Serverless y desacoplado, ideal para crecer con nuevos casos de uso.
- **Gobernado:** Control de calidad, anonimizaci√≥n y logs de trazabilidad incluidos.
- **Seguro:** Accesos controlados por zona, datos sensibles protegidos.
- **Auditable:** M√©tricas y cat√°logos autom√°ticos con registro de cada paso.

---

## üöÄ Pr√≥ximos pasos

- Establecer control de versiones y particiones por fecha de ingesta.
- Automatizar validaciones adicionales de esquema.
- Integrar monitoreo centralizado con CloudWatch.

---

## üë• P√∫blico objetivo

Este framework est√° dise√±ado para:

- **Data Engineers** que necesiten incorporar nuevos or√≠genes de datos r√°pidamente.
- **L√≠deres t√©cnicos** que buscan establecer una arquitectura de ingesta escalable y gobernada.
- **Analistas y Cient√≠ficos de Datos**, que requieren acceso seguro a datos confiables y anonimizados.

---

## üì¨ Contacto

Para dudas o contribuciones, por favor contacta al equipo de Data Engineering.

